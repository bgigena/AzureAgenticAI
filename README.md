# üöÄ Azure AI Agent Infrastructure - Production Ready

Este repositorio contiene la **Arquitectura de Referencia (IaC)** para desplegar agentes de Inteligencia Artificial Generativa en Microsoft Azure, priorizando la seguridad de datos corporativos, la observabilidad de costos y el escalamiento empresarial.

## üåü Propuesta de Valor

A diferencia de los despliegues est√°ndar, este kit de infraestructura implementa las mejores pr√°cticas de **Cloud Adoption Framework (CAF)** y **Well-Architected Framework** para IA:

-   **Zero-Trust Security:** Eliminaci√≥n de API Keys mediante el uso de **Managed Identities** y **RBAC** (Role-Based Access Control).
-   **Enterprise RAG Ready:** Despliegue automatizado de **Azure AI Search** para arquitecturas de Recuperaci√≥n Aumentada por Generaci√≥n.
-   **Observabilidad Total (LLMOps):** Integraci√≥n con **Application Insights** y **Log Analytics** para monitorear latencia, consumo de tokens y trazas de ejecuci√≥n.
-   **Cost Governance:** Configuraci√≥n de cuotas (TPM - Tokens Per Minute) para evitar sorpresas en la facturaci√≥n.

---

## üèóÔ∏è Arquitectura Desplegada

El stack t√©cnico incluye:
1.  **Azure OpenAI Service:** Instancia privada de modelos (GPT-4o / GPT-o1).
2.  **Azure AI Search:** Base de datos vectorial de alto rendimiento.
3.  **Azure Monitor & App Insights:** Telemetr√≠a avanzada para LLMs.
4.  **Identity:** Asignaci√≥n autom√°tica de roles para el usuario/servicio que realiza el despliegue.

---

## üõ†Ô∏è C√≥mo Utilizar este Kit

### Requisitos Previos
-   [Terraform](https://www.terraform.io/downloads.html) >= 1.5.0
-   [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli)
-   Una suscripci√≥n activa de Azure con acceso a **Azure OpenAI Service**.

### Pasos para el Despliegue
1. **Clonar el repositorio:**
   ```bash
   git clone [https://github.com/tu-usuario/azure-ai-infrastructure.git](https://github.com/tu-usuario/azure-ai-infrastructure.git)
   cd azure-ai-infrastructure
### 2. Ingestar Documentos (RAG)

#### En Cloud

Sub√≠ un PDF a tu Blob Storage (`documents`). El Event Grid disparar√° autom√°ticamente tu Azure Function (`doc_ingestor_trigger`) y extraer√° texto, generar√° embeddings, y los mandar√° a Azure AI Search.

#### En el entorno Local (Docker + Azurite + Qdrant)

Azurite no dispara eventos autom√°ticamente. Por eso incluimos un script para facilitar la carga.
Abr√≠ tu terminal y ejecut√°:

```powershell
# Ejemplo: Subir un documento txt o pdf al entorno local
pip install azure-storage-blob
python ingestar_local.py ruta/a/tu/archivo.txt
```

Esto va a:
1. Subir el archivo al Storage local (Azurite).
2. Mandar el aviso a tu contenedor (por Puerto 8080) simulando el evento de la nube.
3. El contenedor fragmentar√° el texto y usar√° Ollama para generar los vectores.

**¬øD√≥nde veo mis documentos guardados?**
- **Archivo Original:** Descarg√° Microsoft Azure Storage Explorer, conectate a "Emulator" y busc√° el contenedor `documents`.
- **Vectores y Chunks:** Entr√° a [http://localhost:6333/dashboard](http://localhost:6333/dashboard) en tu navegador para ver la base de datos vectorial Qdrant gr√°ficamente.

## üíª Desarrollo Local Completo (Docker + Ollama)

Para reducir costos de desarrollo, facilitar el testing o desplegar la soluci√≥n en una computadora nueva de forma 100% local, el sistema soporta un entorno offline contenedorizado.

**Componentes locales:**
- **Almacenamiento:** Azurite (Emulador de Azure Blob Storage).
- **Vector DB:** Qdrant (Base de datos vectorial Open Source).
- **LLM y Embeddings:** Ollama (Modelos ejecut√°ndose en CPU/GPU local).

### Pasos para Desplegar en una Computadora Nueva

#### 1. Instalar Pre-Requisitos
1. Instal√° **Docker Desktop** (Asegurate de que est√© corriendo).
2. Instal√° **Ollama** desde [ollama.com](https://ollama.com/)
3. Instal√° **Python 3.11+**

#### 2. Descargar Modelos de IA
Abr√≠ una terminal (PowerShell o CMD) y ejecut√° estos comandos para descargar los modelos que usa el agente localmente:
```powershell
ollama pull llama3
ollama pull nomic-embed-text
```
*(Nota: El comando `ollama serve` no suele ser necesario en Windows ya que Ollama correo como un servicio en segundo plano autom√°ticamente).*

#### 3. Iniciar la Infraestructura
En la ra√≠z del proyecto (donde est√° el archivo `docker-compose.yml`), ejecut√°:
```powershell
docker-compose up -d --build
```
Esto levantar√° 4 contenedores: la UI, la funci√≥n de ingesta, la base de datos Qdrant y el emulador Azurite. Pod√©s verificar que todos est√©n verdes en Docker Desktop.

#### 4. Probar la UI
Ingres√° a [http://localhost:8501](http://localhost:8501). Vas a ver la interfaz del agente. Asegurate de que en el panel lateral est√© seleccionado "Local" y "Qdrant". 

#### 5. Ingestar tu Primer Documento
Por defecto la base de datos est√° vac√≠a. Para que el agente pueda responder preguntas, necesit√°s cargarle conocimiento.

1. Abr√≠ tu terminal en la carpeta del proyecto.
2. Instal√° el SDK de Azure (solo la primera vez):
   ```powershell
   pip install azure-storage-blob
   ```
3. Ejecut√° el script de ingesta apuntando a cualquier archivo `.txt` que tengas:
   ```powershell
   python ingestar_local.py ruta/a/tu/archivo.txt
   ```
   *El script subir√° el archivo a tu storage local y simular√° el evento en la nube para despertar al contenedor ingestor, el cual calcular√° los vectores v√≠a Ollama usando tu CPU y los guardar√° en Qdrant.*

#### 6. Observar los Datos
- **Los vectores:** Pod√©s ver tu base de datos y c√≥mo se parti√≥ el texto entrando a [http://localhost:6333/dashboard](http://localhost:6333/dashboard) en tu navegador e ingresando a la colecci√≥n `documents`.
- **Los archivos originales:** Descarg√° *Microsoft Azure Storage Explorer*, conectate al "Local Emulator" y vas a ver un contenedor `documents` con tus `.txt` originales.